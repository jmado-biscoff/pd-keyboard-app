{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311de9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, numpy as np, torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c57ba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Paths & hyperparams\n",
    "# -----------------------\n",
    "\n",
    "def find_project_root() -> str:\n",
    "    \"\"\"\n",
    "    Try current dir and up to 4 parents to locate a folder that contains 'backend/ml/dataset/raw'.\n",
    "    If not found, return current working directory.\n",
    "    \"\"\"\n",
    "    cwd = os.getcwd()\n",
    "    candidates = [cwd]\n",
    "    # try parents\n",
    "    cur = cwd\n",
    "    for _ in range(4):\n",
    "        cur = os.path.dirname(cur)\n",
    "        if cur and cur not in candidates:\n",
    "            candidates.append(cur)\n",
    "    for base in candidates:\n",
    "        raw_dir = os.path.join(base, \"backend\", \"ml\", \"dataset\", \"raw\")\n",
    "        if os.path.isdir(raw_dir):\n",
    "            return base\n",
    "    return cwd\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, \"backend\", \"ml\", \"dataset\", \"processed\")\n",
    "MODEL_DIR = os.path.join(PROJECT_ROOT, \"backend\", \"ml\", \"models\")\n",
    "EVAL_DIR  = os.path.join(PROJECT_ROOT, \"backend\", \"ml\", \"evaluation\")\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(EVAL_DIR, exist_ok=True)\n",
    "\n",
    "DEVICE      = torch.device(\"cpu\")\n",
    "BATCH_SIZE  = 64\n",
    "EPOCHS      = 50\n",
    "PATIENCE    = 5\n",
    "LR          = 1e-3\n",
    "HIDDEN_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "649368b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes  X:(6241, 32, 3)  y:(6241, 32)  | SEQ_LEN=32, FEATS=3, CLASSES=2\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Load processed arrays\n",
    "# -----------------------\n",
    "def must(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing: {path}\\n\"\n",
    "            f\"Run your preprocessing first to generate X_*.npy / y_*.npy in {DATA_DIR}\"\n",
    "        )\n",
    "    return path\n",
    "\n",
    "X_train = np.load(must(os.path.join(DATA_DIR, \"X_train.npy\"))).astype(np.float32, copy=False)\n",
    "y_train = np.load(must(os.path.join(DATA_DIR, \"y_train.npy\"))).astype(np.int64,   copy=False)\n",
    "X_val   = np.load(must(os.path.join(DATA_DIR, \"X_val.npy\"  ))).astype(np.float32, copy=False)\n",
    "y_val   = np.load(must(os.path.join(DATA_DIR, \"y_val.npy\"  ))).astype(np.int64,   copy=False)\n",
    "X_test  = np.load(must(os.path.join(DATA_DIR, \"X_test.npy\" ))).astype(np.float32, copy=False)\n",
    "y_test  = np.load(must(os.path.join(DATA_DIR, \"y_test.npy\" ))).astype(np.int64,   copy=False)\n",
    "\n",
    "cfg_path = os.path.join(DATA_DIR, \"feature_config.json\")\n",
    "if os.path.exists(cfg_path):\n",
    "    with open(cfg_path, \"r\") as f:\n",
    "        feat_cfg = json.load(f)\n",
    "else:\n",
    "    feat_cfg = {\n",
    "        \"seq_len\": int(X_train.shape[1]),\n",
    "        \"features\": [f\"f{i}\" for i in range(X_train.shape[2])]\n",
    "    }\n",
    "\n",
    "SEQ_LEN     = int(X_train.shape[1])\n",
    "INPUT_SIZE  = int(X_train.shape[2])\n",
    "NUM_CLASSES = int(max(y_train.max(), y_val.max(), y_test.max()) + 1)  # usually 2\n",
    "\n",
    "print(f\"Shapes  X:{X_train.shape}  y:{y_train.shape}  | SEQ_LEN={SEQ_LEN}, FEATS={INPUT_SIZE}, CLASSES={NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70a6c4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Datasets / Loaders\n",
    "# -----------------------\n",
    "Xtr_t, ytr_t = torch.tensor(X_train), torch.tensor(y_train)\n",
    "Xva_t, yva_t = torch.tensor(X_val),   torch.tensor(y_val)\n",
    "Xte_t, yte_t = torch.tensor(X_test),  torch.tensor(y_test)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(Xtr_t, ytr_t), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(TensorDataset(Xva_t, yva_t), batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader  = DataLoader(TensorDataset(Xte_t, yte_t), batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94601f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Model: BiLSTM + Linear (emissions) + CRF\n",
    "# -----------------------\n",
    "try:\n",
    "    from torchcrf import CRF\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"Missing dependency 'pytorch-crf'. Install it: pip install pytorch-crf\") from e\n",
    "\n",
    "class BiLSTMEmissions(nn.Module):\n",
    "    \"\"\"BiLSTM + Linear → emissions [B,T,C]. Exportable to ONNX.\"\"\"\n",
    "    def __init__(self, in_dim, hidden=128, classes=2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(in_dim, hidden, batch_first=True, bidirectional=True)\n",
    "        self.emission = nn.Linear(2*hidden, classes)\n",
    "    def forward(self, x):              # x: [B,T,F]\n",
    "        h, _ = self.lstm(x)            # [B,T,2H]\n",
    "        logits = self.emission(h)      # [B,T,C]\n",
    "        return logits\n",
    "\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "    \"\"\"Wrap emissions + CRF (CRF used during train/eval; not exported).\"\"\"\n",
    "    def __init__(self, in_dim, hidden=128, classes=2):\n",
    "        super().__init__()\n",
    "        self.emitter = BiLSTMEmissions(in_dim, hidden, classes)\n",
    "        self.crf = CRF(classes, batch_first=True)\n",
    "    def forward(self, x, tags=None, mask=None):\n",
    "        emissions = self.emitter(x)        # [B,T,C]\n",
    "        if tags is None:\n",
    "            paths = self.crf.decode(emissions, mask=mask)   # List[List[int]]\n",
    "            return emissions, paths\n",
    "        nll = -self.crf(emissions, tags, mask=mask, reduction='mean')\n",
    "        return emissions, nll\n",
    "\n",
    "model = BiLSTM_CRF(INPUT_SIZE, hidden=HIDDEN_SIZE, classes=NUM_CLASSES).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "def full_mask(bsz, T, device):\n",
    "    return torch.ones(bsz, T, dtype=torch.bool, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80d92beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train NLL 21.6631 | val NLL 21.1997\n",
      "Epoch 02 | train NLL 20.8764 | val NLL 20.6090\n",
      "Epoch 03 | train NLL 20.3463 | val NLL 19.9642\n",
      "Epoch 04 | train NLL 19.6006 | val NLL 19.4312\n",
      "Epoch 05 | train NLL 18.7173 | val NLL 18.7507\n",
      "Epoch 06 | train NLL 17.8868 | val NLL 17.5069\n",
      "Epoch 07 | train NLL 17.3391 | val NLL 17.5092\n",
      "Epoch 08 | train NLL 17.1598 | val NLL 17.9793\n",
      "Epoch 09 | train NLL 17.7456 | val NLL 17.2300\n",
      "Epoch 10 | train NLL 16.9622 | val NLL 16.6144\n",
      "Epoch 11 | train NLL 16.3615 | val NLL 16.0724\n",
      "Epoch 12 | train NLL 16.0763 | val NLL 17.1467\n",
      "Epoch 13 | train NLL 16.0771 | val NLL 15.5945\n",
      "Epoch 14 | train NLL 15.1321 | val NLL 14.8966\n",
      "Epoch 15 | train NLL 14.9838 | val NLL 14.6148\n",
      "Epoch 16 | train NLL 14.3394 | val NLL 13.9647\n",
      "Epoch 17 | train NLL 13.8617 | val NLL 13.4894\n",
      "Epoch 18 | train NLL 13.2215 | val NLL 13.2063\n",
      "Epoch 19 | train NLL 12.8714 | val NLL 13.2211\n",
      "Epoch 20 | train NLL 12.4343 | val NLL 12.2358\n",
      "Epoch 21 | train NLL 12.1123 | val NLL 11.9164\n",
      "Epoch 22 | train NLL 11.7216 | val NLL 11.5257\n",
      "Epoch 23 | train NLL 11.5521 | val NLL 11.8087\n",
      "Epoch 24 | train NLL 11.2381 | val NLL 10.8431\n",
      "Epoch 25 | train NLL 10.7682 | val NLL 10.9673\n",
      "Epoch 26 | train NLL 10.5725 | val NLL 10.3129\n",
      "Epoch 27 | train NLL 10.3507 | val NLL 10.0960\n",
      "Epoch 28 | train NLL 9.9599 | val NLL 9.9011\n",
      "Epoch 29 | train NLL 9.6506 | val NLL 9.6031\n",
      "Epoch 30 | train NLL 9.4013 | val NLL 9.7209\n",
      "Epoch 31 | train NLL 9.1851 | val NLL 9.4624\n",
      "Epoch 32 | train NLL 9.0032 | val NLL 8.7843\n",
      "Epoch 33 | train NLL 8.6221 | val NLL 8.5728\n",
      "Epoch 34 | train NLL 8.3672 | val NLL 8.3870\n",
      "Epoch 35 | train NLL 8.1347 | val NLL 8.4326\n",
      "Epoch 36 | train NLL 8.1327 | val NLL 8.2072\n",
      "Epoch 37 | train NLL 7.8086 | val NLL 8.1892\n",
      "Epoch 38 | train NLL 7.6595 | val NLL 7.6162\n",
      "Epoch 39 | train NLL 7.4179 | val NLL 7.3583\n",
      "Epoch 40 | train NLL 7.1986 | val NLL 7.1978\n",
      "Epoch 41 | train NLL 7.0911 | val NLL 7.0501\n",
      "Epoch 42 | train NLL 6.9532 | val NLL 6.9608\n",
      "Epoch 43 | train NLL 6.7919 | val NLL 7.1951\n",
      "Epoch 44 | train NLL 6.6192 | val NLL 6.5989\n",
      "Epoch 45 | train NLL 6.4429 | val NLL 6.7976\n",
      "Epoch 46 | train NLL 6.2992 | val NLL 6.3764\n",
      "Epoch 47 | train NLL 6.1251 | val NLL 6.7892\n",
      "Epoch 48 | train NLL 5.9819 | val NLL 6.2748\n",
      "Epoch 49 | train NLL 6.0535 | val NLL 6.2000\n",
      "Epoch 50 | train NLL 5.7592 | val NLL 6.1399\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Train (early stopping on val NLL)\n",
    "# -----------------------\n",
    "best_val = float(\"inf\"); patience = 0\n",
    "best_path = os.path.join(MODEL_DIR, \"bilstm_crf_model.pt\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Train\n",
    "    model.train()\n",
    "    tr_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)  # [B,T,F], [B,T]\n",
    "        optimizer.zero_grad()\n",
    "        mask = full_mask(xb.size(0), xb.size(1), DEVICE)\n",
    "        _, nll = model(xb, tags=yb, mask=mask)\n",
    "        nll.backward()\n",
    "        optimizer.step()\n",
    "        tr_loss += nll.item() * xb.size(0)\n",
    "    tr_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # Validate\n",
    "    model.eval()\n",
    "    va_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            mask = full_mask(xb.size(0), xb.size(1), DEVICE)\n",
    "            _, nll = model(xb, tags=yb, mask=mask)\n",
    "            va_loss += nll.item() * xb.size(0)\n",
    "    va_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d} | train NLL {tr_loss:.4f} | val NLL {va_loss:.4f}\")\n",
    "\n",
    "    if va_loss < best_val:\n",
    "        best_val = va_loss; patience = 0\n",
    "        torch.save(model.state_dict(), best_path)\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience >= PATIENCE:\n",
    "            print(\"Early stopping.\"); break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a56bfa0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics: {'precision': 0.9118659217877095, 'recall': 0.9503027480204937, 'f1_score': 0.9306876496749914}\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Evaluate (CRF decode)\n",
    "# -----------------------\n",
    "model.load_state_dict(torch.load(best_path, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "all_preds, all_tgts = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(DEVICE)\n",
    "        mask = full_mask(xb.size(0), xb.size(1), DEVICE)\n",
    "        emissions, paths = model(xb, tags=None, mask=mask)  # paths: list of length B, each T ints\n",
    "        # stack predictions to [B,T]\n",
    "        maxT = xb.size(1)\n",
    "        pred_np = np.array([p[:maxT] for p in paths], dtype=np.int64)\n",
    "        all_preds.append(pred_np)\n",
    "        all_tgts.append(yb.numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds, axis=0).reshape(-1)\n",
    "all_tgts  = np.concatenate(all_tgts,  axis=0).reshape(-1)\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_tgts, all_preds, average='binary')\n",
    "metrics = {\"precision\": float(precision), \"recall\": float(recall), \"f1_score\": float(f1)}\n",
    "with open(os.path.join(EVAL_DIR, \"bilstm_metrics.json\"), \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "print(\"Test metrics:\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0767a7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported ONNX emissions to: c:\\Users\\geloq\\OneDrive\\Desktop\\pd-keyboard-app\\backend\\ml\\models\\bilstm_emitter.onnx\n",
      "Saved feature config to: c:\\Users\\geloq\\OneDrive\\Desktop\\pd-keyboard-app\\backend\\ml\\evaluation\\bilstm_feature_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geloq\\AppData\\Local\\Temp\\ipykernel_27136\\1866289847.py:16: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n",
      "c:\\Users\\geloq\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\onnx\\symbolic_opset9.py:4244: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Export ONNX (emissions only; CRF not exported)\n",
    "# -----------------------\n",
    "# For deployment, we export BiLSTMEmissions to ONNX → get per-timestep logits in Node.js\n",
    "emitter = model.emitter.to(DEVICE)\n",
    "emitter.eval()\n",
    "\n",
    "dummy = torch.randn(1, SEQ_LEN, INPUT_SIZE, device=DEVICE)\n",
    "onnx_path = os.path.join(MODEL_DIR, \"bilstm_emitter.onnx\")\n",
    "\n",
    "try:\n",
    "    import onnx  # ensure installed\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"Missing 'onnx'. Install it: pip install onnx\") from e\n",
    "\n",
    "torch.onnx.export(\n",
    "    emitter, dummy, onnx_path,\n",
    "    input_names=[\"input\"], output_names=[\"logits\"],\n",
    "    dynamic_axes={\"input\": {0:\"batch\", 1:\"seq_len\"},\n",
    "                  \"logits\": {0:\"batch\", 1:\"seq_len\"}},\n",
    "    opset_version=14\n",
    ")\n",
    "print(\"Exported ONNX emissions to:\", onnx_path)\n",
    "\n",
    "# Save feature config (for inference parity)\n",
    "with open(os.path.join(EVAL_DIR, \"bilstm_feature_config.json\"), \"w\") as f:\n",
    "    json.dump({\n",
    "        \"seq_len\": int(SEQ_LEN),\n",
    "        \"features\": feat_cfg.get(\"features\", [f\"f{i}\" for i in range(INPUT_SIZE)])\n",
    "    }, f, indent=2)\n",
    "print(\"Saved feature config to:\", os.path.join(EVAL_DIR, \"bilstm_feature_config.json\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
