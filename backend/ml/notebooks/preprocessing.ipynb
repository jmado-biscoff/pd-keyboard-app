{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e57223d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 files → 8948 rows\n",
      "✅ Preprocessing complete. Files saved in: c:\\Users\\geloq\\OneDrive\\Desktop\\pd-keyboard-app\\backend\\ml\\dataset\\processed\n"
     ]
    }
   ],
   "source": [
    "import os, glob, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def find_project_root() -> str:\n",
    "    \"\"\"\n",
    "    Try current dir and up to 4 parents to locate a folder that contains 'backend/ml/dataset/raw'.\n",
    "    If not found, return current working directory.\n",
    "    \"\"\"\n",
    "    cwd = os.getcwd()\n",
    "    candidates = [cwd]\n",
    "    # try parents\n",
    "    cur = cwd\n",
    "    for _ in range(4):\n",
    "        cur = os.path.dirname(cur)\n",
    "        if cur and cur not in candidates:\n",
    "            candidates.append(cur)\n",
    "    for base in candidates:\n",
    "        raw_dir = os.path.join(base, \"backend\", \"ml\", \"dataset\", \"raw\")\n",
    "        if os.path.isdir(raw_dir):\n",
    "            return base\n",
    "    return cwd\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "RAW_DIR = os.path.join(PROJECT_ROOT, \"backend\", \"ml\", \"dataset\", \"raw\")\n",
    "PROCESSED_DIR = os.path.join(PROJECT_ROOT, \"backend\", \"ml\", \"dataset\", \"processed\")\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Load & Concatenate Raw CSVs\n",
    "# ---------------------------\n",
    "raw_files = sorted(glob.glob(os.path.join(RAW_DIR, \"*.csv\")))\n",
    "if not raw_files:\n",
    "    raise FileNotFoundError(f\"No raw CSV files found in {RAW_DIR}\")\n",
    "\n",
    "dfs = []\n",
    "for fp in raw_files:\n",
    "    df = pd.read_csv(fp, on_bad_lines='skip')  # skip malformed lines\n",
    "    dfs.append(df)\n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "print(f\"Loaded {len(dfs)} files → {data.shape[0]} rows\")\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Basic Feature Engineering\n",
    "# ---------------------------\n",
    "# Example features — adapt to your dataset columns if needed\n",
    "data[\"Hold_Time\"] = data[\"Release_Time\"] - data[\"Press_Time\"]\n",
    "features = [\"Press_Time\", \"Release_Time\", \"Hold_Time\"]\n",
    "X = data[features].values\n",
    "y = (data[\"Hold_Time\"] > data[\"Hold_Time\"].median()).astype(int).values  # example label\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Scale + Split + Reshape to sequences\n",
    "# ---------------------------\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "SEQ_LEN = 32\n",
    "num_samples = X_scaled.shape[0] - SEQ_LEN\n",
    "X_seq = np.array([X_scaled[i:i+SEQ_LEN] for i in range(num_samples)])\n",
    "y_seq = np.array([y[i:i+SEQ_LEN] for i in range(num_samples)])\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_seq, y_seq, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Save arrays & config\n",
    "# ---------------------------\n",
    "np.save(os.path.join(PROCESSED_DIR, \"X_train.npy\"), X_train)\n",
    "np.save(os.path.join(PROCESSED_DIR, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(PROCESSED_DIR, \"X_val.npy\"), X_val)\n",
    "np.save(os.path.join(PROCESSED_DIR, \"y_val.npy\"), y_val)\n",
    "np.save(os.path.join(PROCESSED_DIR, \"X_test.npy\"), X_test)\n",
    "np.save(os.path.join(PROCESSED_DIR, \"y_test.npy\"), y_test)\n",
    "\n",
    "with open(os.path.join(PROCESSED_DIR, \"feature_config.json\"), \"w\") as f:\n",
    "    json.dump({\n",
    "        \"seq_len\": SEQ_LEN,\n",
    "        \"features\": features,\n",
    "        \"scaler_mean\": scaler.mean_.tolist(),\n",
    "        \"scaler_scale\": scaler.scale_.tolist()\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"✅ Preprocessing complete. Files saved in:\", PROCESSED_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
