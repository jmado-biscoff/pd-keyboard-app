{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19807099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d134f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Paths & hyperparams\n",
    "# -----------------------\n",
    "\n",
    "def find_project_root() -> str:\n",
    "    \"\"\"\n",
    "    Try current dir and up to 4 parents to locate a folder that contains 'backend/ml/dataset/raw'.\n",
    "    If not found, return current working directory.\n",
    "    \"\"\"\n",
    "    cwd = os.getcwd()\n",
    "    candidates = [cwd]\n",
    "    # try parents\n",
    "    cur = cwd\n",
    "    for _ in range(4):\n",
    "        cur = os.path.dirname(cur)\n",
    "        if cur and cur not in candidates:\n",
    "            candidates.append(cur)\n",
    "    for base in candidates:\n",
    "        raw_dir = os.path.join(base, \"backend\", \"ml\", \"dataset\", \"raw\")\n",
    "        if os.path.isdir(raw_dir):\n",
    "            return base\n",
    "    return cwd\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, \"backend\", \"ml\", \"dataset\", \"processed\")\n",
    "MODEL_DIR = os.path.join(PROJECT_ROOT, \"backend\", \"ml\", \"models\")\n",
    "EVAL_DIR  = os.path.join(PROJECT_ROOT, \"backend\", \"ml\", \"evaluation\")\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(EVAL_DIR, exist_ok=True)\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "PATIENCE = 5\n",
    "LR = 1e-3\n",
    "D_MODEL = 64        # Transformer hidden dimension\n",
    "NHEAD = 4\n",
    "NUM_LAYERS = 2\n",
    "FF_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a724c027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes X: (6241, 32, 3), y: (6241, 32)\n",
      "SEQ_LEN=32, INPUT_SIZE=3, CLASSES=2\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Load processed arrays\n",
    "# -----------------------\n",
    "def must(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing: {path}\\nRun preprocessing first to generate npy files.\"\n",
    "        )\n",
    "    return path\n",
    "\n",
    "X_train = np.load(must(os.path.join(DATA_DIR, \"X_train.npy\"))).astype(np.float32)\n",
    "y_train = np.load(must(os.path.join(DATA_DIR, \"y_train.npy\"))).astype(np.int64)\n",
    "X_val   = np.load(must(os.path.join(DATA_DIR, \"X_val.npy\"))).astype(np.float32)\n",
    "y_val   = np.load(must(os.path.join(DATA_DIR, \"y_val.npy\"))).astype(np.int64)\n",
    "X_test  = np.load(must(os.path.join(DATA_DIR, \"X_test.npy\"))).astype(np.float32)\n",
    "y_test  = np.load(must(os.path.join(DATA_DIR, \"y_test.npy\"))).astype(np.int64)\n",
    "\n",
    "cfg_path = os.path.join(DATA_DIR, \"feature_config.json\")\n",
    "with open(cfg_path, \"r\") as f:\n",
    "    feat_cfg = json.load(f)\n",
    "\n",
    "SEQ_LEN = int(X_train.shape[1])\n",
    "INPUT_SIZE = int(X_train.shape[2])\n",
    "NUM_CLASSES = int(max(y_train.max(), y_val.max(), y_test.max()) + 1)\n",
    "\n",
    "print(f\"Shapes X: {X_train.shape}, y: {y_train.shape}\")\n",
    "print(f\"SEQ_LEN={SEQ_LEN}, INPUT_SIZE={INPUT_SIZE}, CLASSES={NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9292bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# DataLoaders\n",
    "# -----------------------\n",
    "Xtr_t, ytr_t = torch.tensor(X_train), torch.tensor(y_train)\n",
    "Xva_t, yva_t = torch.tensor(X_val),   torch.tensor(y_val)\n",
    "Xte_t, yte_t = torch.tensor(X_test),  torch.tensor(y_test)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(Xtr_t, ytr_t), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(TensorDataset(Xva_t, yva_t), batch_size=BATCH_SIZE)\n",
    "test_loader  = DataLoader(TensorDataset(Xte_t, yte_t), batch_size=BATCH_SIZE)\n",
    "\n",
    "# -----------------------\n",
    "# Model: Transformer Encoder for per-timestep classification\n",
    "# -----------------------\n",
    "class TransformerEncoderModel(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, nhead, num_layers, ff_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=ff_dim,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.classifier = nn.Linear(d_model, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_proj(x)         # [B, T, d_model]\n",
    "        x = self.encoder(x)            # [B, T, d_model]\n",
    "        logits = self.classifier(x)    # [B, T, num_classes]\n",
    "        return logits\n",
    "\n",
    "model = TransformerEncoderModel(\n",
    "    input_dim=INPUT_SIZE,\n",
    "    d_model=D_MODEL,\n",
    "    nhead=NHEAD,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    ff_dim=FF_DIM,\n",
    "    num_classes=NUM_CLASSES\n",
    ").to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2e0e180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train 0.6560 | Val 0.5941\n",
      "Epoch 02 | Train 0.5602 | Val 0.5659\n",
      "Epoch 03 | Train 0.4936 | Val 0.3938\n",
      "Epoch 04 | Train 0.4028 | Val 0.3323\n",
      "Epoch 05 | Train 0.3708 | Val 0.2980\n",
      "Epoch 06 | Train 0.3478 | Val 0.3474\n",
      "Epoch 07 | Train 0.3247 | Val 0.2408\n",
      "Epoch 08 | Train 0.2965 | Val 0.2416\n",
      "Epoch 09 | Train 0.3106 | Val 0.3420\n",
      "Epoch 10 | Train 0.2979 | Val 0.2307\n",
      "Epoch 11 | Train 0.2839 | Val 0.1776\n",
      "Epoch 12 | Train 0.2770 | Val 0.3386\n",
      "Epoch 13 | Train 0.2459 | Val 0.3609\n",
      "Epoch 14 | Train 0.3063 | Val 0.2400\n",
      "Epoch 15 | Train 0.2560 | Val 0.2045\n",
      "Epoch 16 | Train 0.2426 | Val 0.1968\n",
      "Early stopping.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Training Loop\n",
    "# -----------------------\n",
    "best_val = float(\"inf\")\n",
    "patience = 0\n",
    "best_model_path = os.path.join(MODEL_DIR, \"transformer_model.pt\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    tr_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)  # [B,T,C]\n",
    "        loss = criterion(logits.view(-1, NUM_CLASSES), yb.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tr_loss += loss.item() * xb.size(0)\n",
    "    tr_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    va_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits.view(-1, NUM_CLASSES), yb.view(-1))\n",
    "            va_loss += loss.item() * xb.size(0)\n",
    "    va_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d} | Train {tr_loss:.4f} | Val {va_loss:.4f}\")\n",
    "\n",
    "    if va_loss < best_val:\n",
    "        best_val = va_loss\n",
    "        patience = 0\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience >= PATIENCE:\n",
    "            print(\"Early stopping.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "732dea92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics: {'precision': 0.9188186749501599, 'recall': 0.9230554261760596, 'f1_score': 0.9209321777922349}\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Evaluation\n",
    "# -----------------------\n",
    "model.load_state_dict(torch.load(best_model_path, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "all_preds, all_tgts = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(DEVICE)\n",
    "        logits = model(xb)\n",
    "        preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "        all_tgts.append(yb.numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds, axis=0).reshape(-1)\n",
    "all_tgts = np.concatenate(all_tgts, axis=0).reshape(-1)\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_tgts, all_preds, average='binary')\n",
    "metrics = {\"precision\": float(precision), \"recall\": float(recall), \"f1_score\": float(f1)}\n",
    "\n",
    "with open(os.path.join(EVAL_DIR, \"transformer_metrics.json\"), \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "print(\"Test metrics:\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32bc3647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geloq\\AppData\\Local\\Temp\\ipykernel_3864\\3160647740.py:12: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported ONNX model to: c:\\Users\\geloq\\OneDrive\\Desktop\\pd-keyboard-app\\backend\\ml\\models\\transformer_model.onnx\n",
      "Saved transformer feature config.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Export to ONNX\n",
    "# -----------------------\n",
    "dummy = torch.randn(1, SEQ_LEN, INPUT_SIZE, device=DEVICE)\n",
    "onnx_path = os.path.join(MODEL_DIR, \"transformer_model.onnx\")\n",
    "\n",
    "try:\n",
    "    import onnx\n",
    "except ImportError:\n",
    "    raise RuntimeError(\"Missing ONNX. Install with: pip install onnx\")\n",
    "\n",
    "torch.onnx.export(\n",
    "    model, dummy, onnx_path,\n",
    "    input_names=[\"input\"], output_names=[\"logits\"],\n",
    "    dynamic_axes={\"input\": {0:\"batch\", 1:\"seq_len\"}, \"logits\": {0:\"batch\", 1:\"seq_len\"}},\n",
    "    opset_version=14\n",
    ")\n",
    "print(\"Exported ONNX model to:\", onnx_path)\n",
    "\n",
    "# Save feature config for inference\n",
    "with open(os.path.join(EVAL_DIR, \"transformer_feature_config.json\"), \"w\") as f:\n",
    "    json.dump({\n",
    "        \"seq_len\": SEQ_LEN,\n",
    "        \"features\": feat_cfg.get(\"features\", [f\"f{i}\" for i in range(INPUT_SIZE)])\n",
    "    }, f, indent=2)\n",
    "print(\"Saved transformer feature config.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
